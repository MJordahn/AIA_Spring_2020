{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#%%\n",
    "f = open('train-images-idx3-ubyte', 'r')\n",
    "a = np.fromfile(f, dtype='>i4', count=4)\n",
    "images = np.fromfile(f, dtype='u1')\n",
    "\n",
    "im = np.reshape(images[0:(28*28)],(28,28))\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.imshow(im)\n",
    "plt.title('MNST')\n",
    "fig.show\n",
    "#%%\n",
    "f = open('train-labels-idx1-ubyte', 'r')\n",
    "t = np.fromfile(f, count = 2, dtype='>i4')\n",
    "labels = np.fromfile(f, dtype='u1')\n",
    "images = images.reshape((int(len(images)/(28*28)), 28*28))\n",
    "images = images.astype(float)\n",
    "images = images/255\n",
    "labels = labels.reshape((len(labels), 1))\n",
    "labels = labels.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "import math\n",
    "def init_weights_bias(neurons_in_layers):\n",
    "    W = []\n",
    "    b = []\n",
    "    for i in range(len(neurons_in_layers)-1):\n",
    "        std = math.sqrt(2)*math.sqrt(2.0/(float(neurons_in_layers[i])+float(neurons_in_layers[i+1])))\n",
    "        W.append(np.random.normal(loc=0.0, scale=std, size=[neurons_in_layers[i],neurons_in_layers[i+1]])) \n",
    "        b.append(np.random.normal(loc=0.0, scale=std, size=[1, neurons_in_layers[i+1]])) \n",
    "    return (W, b)\n",
    "def forward_pass(NN, x):\n",
    "    #x: The input of the network             (np.array of shape: (batch_size, number_of_features))\n",
    "    #NN: The initialized neural network      (tuple of list of matrices)\n",
    "    z = [x]\n",
    "    a = []\n",
    "    for l in range(len(NN[0])):\n",
    "        a.append(np.einsum('bi, io -> bo', z[l], NN[0][l]) + NN[1][l])  # The affine transform x*w+b\n",
    "        if l+1 != len(NN[0]):\n",
    "            z.append(np.maximum(a[l], 0))\n",
    "        else:\n",
    "            z.append(softmax(a[l], axis=1))\n",
    "    return z, a\n",
    "\n",
    "def backward_pass(x, t, z, a, NN):\n",
    "    y = z[-1] #Apply softmax to z to get probability of each class\n",
    "    delta = y-t # Delta for the last layer\n",
    "    d_a = []\n",
    "    for i in range(len(a)):\n",
    "        d_a.append(z[i])\n",
    "    g_w = [] \n",
    "    g_b = []\n",
    "    g_b.append(np.mean(delta, axis=0))\n",
    "    g_w.append(np.mean(np.einsum('bo, bi -> bio', delta, z[-2]), axis=0))\n",
    "    \n",
    "    for l in range(1, len(NN[0])):\n",
    "        d_C_d_z = np.einsum('bo, io -> bi', delta, NN[0][-l])  # Derivative of the Cost with respect to an activated layer d_C_d_z. \n",
    "                                                               #  delta shape: as above; weights shape: (i, o)\n",
    "                                                               # Delta: d_C_d_z (element-wise mult) derivative of the activation layers\n",
    "                                                               #  delta shape: as above; d_z shape: (b, i)  \n",
    "        delta = np.einsum('bi, bi -> bi', d_C_d_z, d_a[-l])     # <- Insert correct expression                                      \n",
    "        g_b.append(np.mean(delta, axis=0)) \n",
    "        g_w.append(np.mean(np.einsum('bo, bi -> bio', delta, z[-l-2]), axis=0)) # Derivative of cost with respect to weights in layer l:\n",
    "                                                                           # delta shape: as above; activations of l-1 shape: (b, i)\n",
    "    return g_b[::-1], g_w[::-1]\n",
    "\n",
    "def normalize_data(data):\n",
    "    print(data[0])\n",
    "    train_mu = np.mean(data, axis=0)\n",
    "    train_sigma = np.std(data, axis=0)\n",
    "    data = data-train_mu/train_sigma\n",
    "    return data\n",
    "    \n",
    "def cross_entropy_loss(target, y, derivative=False):\n",
    "    \"\"\"\n",
    "    Computes the cross entropy loss function and its derivative \n",
    "    Input:\n",
    "    target:      target (expected output)          (np.array)\n",
    "    y:      output from forward pass (np.array, must be the same shape as t)\n",
    "    derivative: whether to return the derivative with respect to y or return the loss (boolean)\n",
    "    \"\"\"\n",
    "    if derivative:\n",
    "        return (y-t)\n",
    "    else:\n",
    "        return -target*np.log(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target_array(data):\n",
    "    new_data = []\n",
    "    for label in data:\n",
    "        labels = []\n",
    "        for i in range(10):\n",
    "            if i == label:\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "        labels = np.array(labels)\n",
    "        new_data.append(labels)\n",
    "    return np.array(new_data)\n",
    "\n",
    "X = images[:1000]\n",
    "T = make_target_array(labels[:1000])\n",
    "layers = [28*28, 500, 100, 10]\n",
    "eta = 0.01\n",
    "NN = init_weights_bias(layers)\n",
    "train_loss = []\n",
    "\n",
    "for i in range(1000):\n",
    "    z, a = forward_pass(NN, X)\n",
    "    g_b, g_w = backward_pass(X, T, z, a, NN)\n",
    "    train_loss.append(np.mean(cross_entropy_loss(T, z[-1])))\n",
    "    for l in range(len(g_b)):\n",
    "            NN[0][l] -= g_w[l]*eta\n",
    "            NN[1][l] -= g_b[l]*eta\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "test_x = images[-100:]\n",
    "test_labels = make_target_array(labels[-100:])\n",
    "z, a = forward_pass(NN, X)\n",
    "\n",
    "correct = 0\n",
    "for pair in zip(z[-1], test_labels):\n",
    "    if np.argmax(pair[0]) == np.argmax(pair[1]):\n",
    "        correct += 1\n",
    " \n",
    "print(\"Accuracy obtained on test set: \" + str(correct/len(test_labels)*100))\n",
    "ax1.plot(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
